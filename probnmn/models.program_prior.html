
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
  <head>
    <meta charset="utf-8" />
    <title>probnmn.models.program_prior &#8212; ProbNMN 0.1 documentation</title>
    <link rel="stylesheet" href="../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/language_data.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="probnmn.models.program_generator" href="models.program_generator.html" />
    <link rel="prev" title="probnmn.models" href="models.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="probnmn-models-program-prior">
<h1>probnmn.models.program_prior<a class="headerlink" href="#probnmn-models-program-prior" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="probnmn.models.program_prior.ProgramPrior">
<em class="property">class </em><code class="descclassname">probnmn.models.program_prior.</code><code class="descname">ProgramPrior</code><span class="sig-paren">(</span><em>vocabulary: allennlp.data.vocabulary.Vocabulary</em>, <em>input_size: int = 256</em>, <em>hidden_size: int = 128</em>, <em>num_layers: int = 2</em>, <em>dropout: float = 0.0</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/kdexd/probnmn-clevr/blob/master/probnmn/models/program_prior.py#L16-L301"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#probnmn.models.program_prior.ProgramPrior" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>A simple language model which learns a prior over all the valid program sequences in CLEVR
v1.0 training split.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>vocabulary: allennlp.data.vocabulary.Vocabulary</strong></dt><dd><p>AllenNLP’s vocabulary. This vocabulary has three namespaces - “questions”, “programs” and
“answers”, which contain respective token to integer mappings.</p>
</dd>
<dt><strong>input_size: int, optional (default = 256)</strong></dt><dd><p>The dimension of the inputs to the LSTM.</p>
</dd>
<dt><strong>hidden_size: int, optional (default = 256)</strong></dt><dd><p>The dimension of the outputs of the LSTM.</p>
</dd>
<dt><strong>num_layers: int, optional (default = 2)</strong></dt><dd><p>Number of recurrent layers in the LSTM.</p>
</dd>
<dt><strong>dropout: float, optional (default = 0.0)</strong></dt><dd><p>Dropout probability for the outputs of LSTM at each layer except last.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="classmethod">
<dt id="probnmn.models.program_prior.ProgramPrior.from_config">
<em class="property">classmethod </em><code class="descname">from_config</code><span class="sig-paren">(</span><em>config: probnmn.config.Config</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/kdexd/probnmn-clevr/blob/master/probnmn/models/program_prior.py#L67-L78"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#probnmn.models.program_prior.ProgramPrior.from_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Instantiate this class directly from a <a class="reference internal" href="config.html#probnmn.config.Config" title="probnmn.config.Config"><code class="xref py py-class docutils literal notranslate"><span class="pre">Config</span></code></a>.</p>
</dd></dl>

<dl class="method">
<dt id="probnmn.models.program_prior.ProgramPrior.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>program_tokens: torch.Tensor</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/kdexd/probnmn-clevr/blob/master/probnmn/models/program_prior.py#L80-L155"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#probnmn.models.program_prior.ProgramPrior.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Given tokenized program sequences padded upto maximum length, predict sequence at next
time-step and calculate cross entropy loss of this predicted sequence.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>program_tokens: torch.Tensor</strong></dt><dd><p>Tokenized program sequences padded with zeroes upto maximum length.
shape: (batch_size, max_sequence_length)</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl>
<dt><strong>Dict[str, torch.Tensor]</strong></dt><dd><p>Predictions of next time-step and cross entropy loss (by teacher forcing), a dict
with structure:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="s2">&quot;predictions&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="p">(</span><span class="n">shape</span><span class="p">:</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">max_sequence_length</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)),</span>
    <span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="p">(</span><span class="n">shape</span><span class="p">:</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="p">))</span>
<span class="p">}</span>
</pre></div>
</div>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="probnmn.models.program_prior.ProgramPrior.get_metrics">
<code class="descname">get_metrics</code><span class="sig-paren">(</span><em>reset: bool = True</em><span class="sig-paren">)</span> &#x2192; Dict[str, float]<a class="reference external" href="http://github.com/kdexd/probnmn-clevr/blob/master/probnmn/models/program_prior.py#L157-L172"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#probnmn.models.program_prior.ProgramPrior.get_metrics" title="Permalink to this definition">¶</a></dt>
<dd><p>Return perplexity using the accumulated loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>reset: bool, optional (default = True)</strong></dt><dd><p>Whether to reset the accumulated metrics after retrieving them.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>Dict[str, float]</strong></dt><dd><p>A dictionary with metrics <code class="docutils literal notranslate"><span class="pre">{&quot;perplexity&quot;}</span></code>.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="probnmn.models.program_prior.ProgramPrior.sample">
<code class="descname">sample</code><span class="sig-paren">(</span><em>num_samples: int = 1</em>, <em>max_sequence_length: int = 28</em><span class="sig-paren">)</span> &#x2192; Dict[str, torch.Tensor]<a class="reference external" href="http://github.com/kdexd/probnmn-clevr/blob/master/probnmn/models/program_prior.py#L174-L301"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#probnmn.models.program_prior.ProgramPrior.sample" title="Permalink to this definition">¶</a></dt>
<dd><p>Using &#64;start&#64; token at first time-step, perform categorical sampling and sample program
sequences freely, all sequences would be padded after encountering first &#64;end&#64; token.</p>
<p>This method is mainly useful in checking coherence and sensitivity of our model’s beliefs.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>num_samples: int, optional (default = 1)</strong></dt><dd><p>Number of program_samples to generate.</p>
</dd>
<dt><strong>max_sequence_length: int, optional (default = 28)</strong></dt><dd><p>Maximum decoding steps while sampling programs. This includes &#64;start&#64; token. Output
sequences will be one time-step smaller, excluding &#64;start&#64;.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl>
<dt><strong>Dict[str, torch.Tensor]</strong></dt><dd><p>A dict with predictions and sequence log-probabilities (averaged across time-steps).
This would acutally return negative log-probabilities and name it “loss” for API
consistency. The dict structure looks like:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="s2">&quot;predictions&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="p">(</span><span class="n">shape</span><span class="p">:</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">max_sequence_length</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)),</span>
    <span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="p">(</span><span class="n">shape</span><span class="p">:</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="p">))</span>
<span class="p">}</span>
</pre></div>
</div>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">ProbNMN</a></h1>








<h3>Navigation</h3>
<p class="caption"><span class="caption-text">Contents</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="config.html">probnmn.config</a></li>
<li class="toctree-l1"><a class="reference internal" href="data.html">probnmn.data</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="models.html">probnmn.models</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">probnmn.models.program_prior</a></li>
<li class="toctree-l2"><a class="reference internal" href="models.program_generator.html">probnmn.models.program_generator</a></li>
<li class="toctree-l2"><a class="reference internal" href="models.question_reconstructor.html">probnmn.models.question_reconstructor</a></li>
<li class="toctree-l2"><a class="reference internal" href="models.nmn.html">probnmn.models.nmn</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="modules.html">probnmn.modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="trainers.html">probnmn.trainers</a></li>
<li class="toctree-l1"><a class="reference internal" href="evaluators.html">probnmn.evaluators</a></li>
<li class="toctree-l1"><a class="reference internal" href="utils.html">probnmn.utils</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  <li><a href="models.html">probnmn.models</a><ul>
      <li>Previous: <a href="models.html" title="previous chapter">probnmn.models</a></li>
      <li>Next: <a href="models.program_generator.html" title="next chapter">probnmn.models.program_generator</a></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2019, Karan Desai.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 2.0.0</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../_sources/probnmn/models.program_prior.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>